---
title: "Analyzing IMDb Ratings of Scooby-Doo Episodes"
author: "Regression Rockstars: James Cai, Steph Reinke, Sarah Wu, Michael Zhou"
date: "December 1, 2023"
format: pdf
execute: 
  warning: false
  message: false
  echo: false
editor: visual
---

```{r}
#| label: load-pkg-data
#| warning: false
#| message: false

library(tidyverse)
library(tidymodels)
library(knitr) 
library(patchwork)
library(skimr)

scoobydoo <- read_csv("data/Scooby-Doo Completed.csv")
```

# Introduction and Data:

## Introduction

Scooby-Doo is a popular animated TV show that follows a group of teenagers and a talking Great Dane, Scooby-Doo, as they solve mysteries involving supernatural monsters and creatures. Each episode typically involves seeking and scheming to find the villain, ending with a dramatic unmasking of the monster. The show focuses on themes of friendship and teamwork. The show originally aired on CBS from 1969 - 1976, but there have been many sub-series and reboots since.

We are interested in researching Scoody-Doo IMDb ratings because we all enjoyed Scooby-Doo in our childhoods. We also think that finding certain predictors of animated TV series ratings is useful for the entertainment industry. Specifically, our findings could be useful to anyone looking to create an animated TV series and wanting to know what aspects make up a successful episode. In the paper, "Determining and Evaluating The Most Popular Cartoons Among Children Between 4 and 6 Years of Age" published in 2017, the authors criticize the use of violence, vulgar language, and horror music in Scooby-Doo ([BaÅŸal et. al. 2017](https://www.researchgate.net/publication/318108700_Determining_and_Evaluating_The_Most_Popular_Cartoons_Among_Children_Between_4_and_6_Years_of_Age)), yet we can't ignore the huge impact and popularity of Scooby-Doo. In 2013, Scooby-Doo was ranked the fifth greatest cartoon of all time ([TVGuide 2013](https://www.foxnews.com/entertainment/tv-guide-magazines-60-greatest-cartoons-of-all-time)). If Scooby-Doo continues to create spin-off shows, our findings about what makes a successful episode could inform their future episodes as well.

Our primary research question is what factors best explain the variability in the IMDb ratings of Scooby-Doo episodes? In other words, what elements tend to contribute to a successful episode? We want to investigate how various predictor variables in the dataset like `monster.amount`, character that unmasks the villain (`unmask.fred`, and such for all five characters part of the main group), `network`, and more, adequately explain the variability in IMDb ratings. We hypothesize that episodes with a higher monster count will have a better rating since we think that there is more action and suspense in episodes with more monsters. We think that episodes where Fred unmasked the villain will have a higher rating since he is the leader of the group and thus, we think that people will be more drawn to him. Finally, we think that episodes that aired on Cartoon Network will have a better rating since we think that Cartoon Network can generate more positive responses since they specialize in cartoons and are pretty well-known. In our analysis, we would like to explore the interaction between these variables as well as consider other predictors in the dataset.

## Data

This Scooby-Doo data was found on the [TidyTuesday](https://github.com/rfordatascience/tidytuesday/blob/master/data/2021/2021-07-13/readme.md#scooby-doo-episodes) database on Github. The data originally came from [Kaggle](https://www.kaggle.com/datasets/williamschooleman/scoobydoo-complete) and was manually aggregated by user [Plummye](https://www.kaggle.com/williamschooleman) in 2021. The curator took roughly one year to watch every Scooby-Doo iteration and track every variable in this dataset. It is noted that some of the values are subjective by the nature of watching, but the original data curator tried to keep the data collection consistent across the different episodes.

Each observation represents an episode from a rendition of the Scooby-Doo franchise up until February 25, 2021, including movies and specials. The variables that were measured include the series and episode name (which we will not use as predictor variables), network aired on, IMDb rating, engagement (represented by the number of reviews on IMDb), and many details about what happened in each episode, such as how many monsters appeared, which character captured and unmasked the monster, the terrain of the episode, and more. There is a mix of both numerical and categorical characteristics.

The unmask variable is in the data as 6 separate columns with each column representing a person, such as `unmask.fred`, `unmask.velma`, etc. Before any of our analyses, we combined these columns into one singular column, `unmask_villain`. We also converted `imdb` from a `character` to a `double` as we want it to be a quantitative value.

Our response variable is `imdb`, while after careful consideration, our predictor variables are `unmask_villain`, `monster.amount`, and `network`.

`imdb`: double, represents the rating on IMDb

`unmask_villain`: character, represents which character unmasked the villain (if any)

`monster.amount`: double, represents the number of monsters in the episode

`network`: character, represents the network the episode was aired on

```{r cleaning}
#| warning: false
scoobydoo <- mutate(scoobydoo, unmask_villain = 
                           ifelse(unmask.fred == TRUE, "Fred",
                           ifelse(unmask.daphnie == TRUE, "Daphne",
                           ifelse(unmask.velma == TRUE, "Velma",
                           ifelse(unmask.shaggy == TRUE, "Shaggy",
                           ifelse(unmask.scooby == TRUE, "Scooby", 
                           ifelse(unmask.other == TRUE, "Other", "None")))))))

scoobydoo <- scoobydoo |>
  mutate(imdb = as.numeric(imdb))
```

## Exploratory Data Analysis

```{r response-dist}
#| warning: false
#| message: false

e1 <- scoobydoo |>
  ggplot(aes(x = imdb)) +
  geom_histogram() +
  labs(x = "IMDb Rating",
       y = "Frequency",
       title = "IMDb Rating",
       caption = "Figure 1") +
  theme_minimal() +
    theme(plot.title = element_text(size=8)) +
  theme(axis.title.x = element_text(size=8)) +
  theme(axis.title.y = element_text(size=8))
```

```{r response-stats}
#| include = FALSE

scoobydoo |>
  skim(imdb) |>
  select(-skim_type, -skim_variable, -complete_rate,
         - numeric.hist) |> #remove these columns from output
  print(width = Inf) #print all columns
```

```{r qualpred-dist}
#| warning: false
#| message: false

e2 <- scoobydoo |>
  ggplot(aes(x = monster.amount)) +
  geom_histogram(bins=7) +
  labs(x = "Number of Monsters",
       title = "Number of Monsters",
       caption = "Figure 2") +
  theme_minimal() +
    theme(plot.title = element_text(size=8)) +
  theme(axis.title.x = element_text(size=8)) +
  theme(axis.title.y = element_text(size=8)) +
  theme(axis.title.y = element_blank())
```

```{r qualpred-stats}
#| include = FALSE

scoobydoo |>
  skim(monster.amount) |>
  select(-skim_type, -skim_variable, -complete_rate,
         - numeric.hist) |> #remove these columns from output
  print(width = Inf) #print all columns
```

```{r unmask-dist}

e3 <- scoobydoo |>
  ggplot(aes(x = unmask_villain)) +
  geom_bar() +
  labs(x = "Character",
       title = "Unmasked By",
       caption = "Figure 3") +
  theme_minimal() +
    theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1, size = 6)) +
  theme(plot.title = element_text(size=8)) +
  theme(axis.title.x = element_text(size=8)) +
  theme(axis.title.y = element_text(size=8)) +
  theme(axis.title.y = element_blank())
```

```{r catpred-dist}

e4 <- scoobydoo |>
  ggplot(aes(x = network)) +
  geom_bar() +
  labs(x = "Network",
       title = "Network",
       caption = "Figure 4") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1, size = 5)) +
  theme(plot.title = element_text(size=8)) +
  theme(axis.title.x = element_text(size=8)) +
  theme(axis.title.y = element_text(size=8)) +
  theme(axis.title.y = element_blank())
```

```{r showgraphs, out.width = "102%"}

e1 | e2 | e3 | e4
```

Figure 1: The distribution of our response variable IMDb ratings, `imdb`, is unimodal and roughly symmetrical. The mean is 7.278 and the standard deviation is 0.732. The minimum is 4.2 and the maximum is 9.6. There do not seem to be any significant outliers.

Figure 2: The distribution of the number of monsters, `monster.amount`, is unimodal and right-skewed. The median is 1 monster and the IQR is 1 monster. The minimum is 0 monsters and the maximum is 19 monsters. There are a few episodes with notably high amounts of monsters, with 5 episodes having 13 or more monsters.

Figure 3: The distribution of who unmasks the villain, `unmask_villain`, shows that in a good majority of the episodes, no one unmasked the villain. However, out of the episodes where a villain was unmasked, Fred and Velma were the main characters who unmasked the villain.

Figure 4: The distribution of the network the episode aired on, `network`, shows that a good majority of the episodes aired on ABC. There were also considerable amounts of episodes that aired on Cartoon Network and Boomerang, while there are also networks that aired very few episodes, such as TBC and Adult Swim.

```{r qual}
#| warning: false

e5 <- scoobydoo |>
  ggplot(aes(x = as.factor(monster.amount), y = imdb)) +
  geom_boxplot(outlier.size = 0.5) +
  labs(x = "Number of Monsters",
       y = "IMDb Rating",
       title = "Relationship between Number of Monsters and IMDb Rating",
       caption = "Figure 5") +
  theme_minimal() +
  theme(plot.title = element_text(size=8)) +
  theme(axis.title.x = element_text(size=8)) +
  theme(axis.title.y = element_text(size=8)) 
```

```{r correlation}
#| include = FALSE

scoobydoo |>
  na.omit(monster.amount) |>
  na.omit(imdb) |>
  summarise(r = cor(monster.amount, imdb)) |> pull()
```

```{r cat2}
#| warning: false
#| message: false

e6 <- scoobydoo |>
  ggplot(aes(x = unmask_villain, y = imdb)) +
  geom_boxplot(outlier.size = 0.5) +
  labs(x = "Who Unmasks the Villain",
       y = "IMDB Rating",
       title = "Relationship between who Unmasks the Villain and IMDB Rating",
       caption = "Figure 6"
       ) +
  theme_minimal() +
  theme(plot.title = element_text(size=8)) +
  theme(axis.title.x = element_text(size=8)) +
  theme(axis.title.y = element_text(size=8))
```

```{r plots, out.width = "75%"}
#| warning: false

e5/e6
```

Figure 5: From the distribution of the different boxplots for each number of total monsters included in `monster.amount`, we observe that many of the interquartile intervals of the boxplots overlap, meaning that their IMDb ratings are quite similar. However, there are still quite a few boxplots that do not overlap with a couple of the other boxplots, signaling that `monster.amount` may have some significant effects.

Figure 6: From the distribution of the different boxplots for each character included in `unmask_villain`, we observe that all of the interquartile intervals of the boxplots overlap, so we should consider whether this variable is important for our model. There are also quite a lot of outliers, especially if no one unmasks the villain.

```{r cat}
#| warning: false
#| message: false

e7 <- scoobydoo |>
  ggplot(aes(x = network, y = imdb)) +
  geom_boxplot(outlier.size = 0.5) +
  labs(x = "Network Aired On",
       y = "IMDb Rating",
       title = "Network and IMDb Rating",
       caption = "Figure 7"
       ) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1, size = 6)) +
      theme(plot.title = element_text(size=8)) +
  theme(axis.title.x = element_text(size=8)) +
  theme(axis.title.y = element_text(size=8))
```

```{r interaction-eda}
#| warning: false
#| message: false

e8 <- scoobydoo |>
  filter(monster.amount < 8 & monster.amount > 0) |>
  ggplot(
    aes(x = as.factor(monster.amount), y = imdb, color = unmask_villain)) +
  geom_point() +
  labs(title = "Number of Monsters and Unmask Villain",
       subtitle = "for 1-7 total monsters",
       x = "Number of Monsters",
       y = "IMDb Rating",
       color = "Unmasked by:",
       caption = "Figure 8") +
  theme_minimal() +
    theme(plot.title = element_text(size=8)) +
  theme(plot.subtitle = element_text(size=6)) +
  theme(legend.title = element_text(size=6)) +
  theme(legend.text = element_text(size=6)) +
  theme(axis.title.x = element_text(size=8)) +
  theme(axis.title.y = element_text(size=8))
```

```{r plots2, out.width= "75%"}

e7 | e8
```

Figure 7: From the distribution of the different boxplots for each network, we again observe that many of the interquartile intervals of the boxplots overlap. It seems that Cartoon Network generally received the best ratings, while Warner Bros. Picture and The CW generally received the worst ratings. We also observe a few outliers in the distribution of IMDb ratings for some networks, such as Warner Home Video and ABC. Many of the networks have IMDb ratings that are pretty symmetrical, as the line representing the median is close to the middle of the box, such as in the case of CBS and The CW, but some are pretty skewed, such as in the case of Syndication, The WB, and Warner Bros. Picture.

Figure 8: Here, we explore the relationship between two of our predictor variables, `monster.amount` and `unmask_villain`. We are only showing a subset of the full relationship between the two variables, since as the number of monsters increases, there is less and less data to observe a relationship. From this graph, we become interested in whether there is a significant relationship between these two variables on IMDb rating--for example, if there's one monster, is the effect on IMDb rating different for whether Fred unmasks the villain or if Velma unmasks the villain?

# Methodology:

Since our response variable is quantitative, we decided to use multiple linear regression for modeling. We also split our original data set into a training (75%) and testing (25%) set to attempt to prevent model overfitting.

Given that our response variable is the IMDb rating of each episode, it is natural to choose predictor variables that have variability for each episode, meaning the predictors should characterize each episode. In this specific case, the plot of Scooby-Doo can be broadly summarized as a team of friends trying to unmask the villain. Thus it is natural to choose variables such as `monster.amount` and `unmask_villain`. We also include `network` in the list of predictors because there is decent variability for this variable, and intuitively, the network an episode takes place in could affect the IMDb rating because there could be slight stylistic differences in each series for different networks. Additionally, we settled on the listed variables because many other variables were difficult to use due to the nature of the input, such as `monster.type`, where episodes with multiple monsters had all the types listed as one character string with a comma separating the different types. Other variables did not make sense to use, such as `title` and `culprit.name`, as we do not think variables like these would make good predictors. Therefore, taking all of these factors into consideration, the predictor variables we settled on were `network`, `monster.amount`, and `unmask_villain`.

From our initial exploratory data analysis, we saw a lot of variation within the relationship between `network` and `imdb`, so we definitely wanted to include `network` as part of our model. The relationships between `monster.amount` and `unmask_villain` each with `imdb` seemed less strong, but since we were still interested in how these predictor variables affected the IMDb rating, we added them to our model. We were also interested if there was a relationship between any of the predictor variables, so we included interaction effects as well.

To compare our models, we plan on using 3-fold cross-validation, and we also included a function to calculate adjusted $R^2$, AIC, and BIC, which we will use when choosing our final model. We will check model conditions in the Results section after choosing our final model through these statistics.

For each model, we decided to create a recipe, where we performed these steps across all models:

1.  Simplified the number of networks in `networks` by using step_other with a threshold of 30 in hopes of ending with a more parsimonious model.
2.  Created dummy variables for all nominal predictors using step_dummy, allowing us to use linear regression for the different levels in each nominal predictor.
3.  Removed predictors with zero variance using step_zv so that our model only includes variables with variability throughout the dataset.

We tested a total of four different models. Since we knew that we wanted to include the variables, `network`, `monster.amount`, and `unmask_villain`, we tested the different interactions between combinations of two of the three predictor variables as shown here.

Model 1: imdb \~ network + monster.amount + unmask_villain with no interaction terms

Model 2: imdb \~ network + monster.amount + unmask_villain with interaction between monster.amount and unmask_villain

Model 3: imdb \~ network + monster.amount + unmask_villain with interaction between monster.amount and network

Model 4: imdb \~ network + monster.amount + unmask_villain with interaction between unmask_villain and network

```{r function}
calc_model_stats <- function(x) {
  glance(extract_fit_parsnip(x)) |>
    select (adj.r.squared, AIC, BIC)
}
```

```{r}
#| label: split

set.seed(6)
data_split <- initial_split(scoobydoo, prop = 0.75)
train_data <- training(data_split)
test_data <- testing(data_split)

set.seed(6)
folds <- vfold_cv(train_data, v = 3)

model_spec <- linear_reg() |>
  set_engine("lm")
```

```{r}
#| label: recipe2

recipe_2 <- recipe(imdb ~ network + monster.amount + unmask_villain,
                    data = train_data) |>
  step_other(network, threshold = 30) |>
  step_interact(terms = ~ monster.amount:unmask_villain) |>
  step_dummy(all_nominal_predictors()) |>
  step_zv(all_predictors())

wflow2 <- workflow() |>
  add_model(model_spec) |>
  add_recipe(recipe_2)
```

```{r}
#| label: recipe3

recipe_3 <- recipe(imdb ~ network + monster.amount + unmask_villain,
                    data = train_data) |>
  step_other(network, threshold = 30) |>
  step_interact(terms = ~ monster.amount:network) |>
  step_dummy(all_nominal_predictors()) |>
  step_zv(all_predictors())

wflow3 <- workflow() |>
  add_model(model_spec) |>
  add_recipe(recipe_3)
```

```{r}
#| label: recipe1

recipe_1 <- recipe(imdb ~ network + monster.amount + unmask_villain,
                    data = train_data) |>
  step_other(network, threshold = 30) |>
  step_dummy(all_nominal_predictors()) |>
  step_zv(all_predictors())

wflow1 <- workflow() |>
  add_model(model_spec) |>
  add_recipe(recipe_1)
```

```{r}
#| label: recipe4

recipe_4 <- recipe(imdb ~ network + monster.amount + unmask_villain,
                    data = train_data) |>
  step_other(network, threshold = 30) |>
  step_interact(terms = ~ unmask_villain:network) |>
  step_dummy(all_nominal_predictors()) |>
  step_zv(all_predictors())

wflow4 <- workflow() |>
  add_model(model_spec) |>
  add_recipe(recipe_4)
```

```{r results='hide'}
#| label: fit

fit_rs1 <- wflow1 |>
  fit_resamples(resamples=folds,
                control = control_resamples(extract = calc_model_stats))

fit_rs2 <- wflow2 |>
  fit_resamples(resamples=folds,
                control = control_resamples(extract = calc_model_stats))

fit_rs3 <- wflow3 |>
  fit_resamples(resamples=folds,
                control = control_resamples(extract = calc_model_stats))

fit_rs4 <- wflow4 |>
  fit_resamples(resamples=folds,
                control = control_resamples(extract = calc_model_stats))

map_df (fit_rs1$.extracts, ~ .x[[1]] [[1]]) |>
  summarise (mean_adj_rsq = mean(adj.r.squared),
             mean_aic = mean(AIC),
             mean_bic = mean (BIC)) |>
  kable(digits = 3, caption = "wflow1")

map_df (fit_rs2$.extracts, ~ .x[[1]] [[1]]) |>
  summarise (mean_adj_rsq = mean(adj.r.squared),
             mean_aic = mean(AIC),
             mean_bic = mean (BIC)) |>
  kable(digits = 3, caption = "wflow2")

map_df (fit_rs3$.extracts, ~ .x[[1]] [[1]]) |>
  summarise (mean_adj_rsq = mean(adj.r.squared),
             mean_aic = mean(AIC),
             mean_bic = mean (BIC)) |>
  kable(digits = 3, caption = "wflow3")

map_df (fit_rs4$.extracts, ~ .x[[1]] [[1]]) |>
  summarise (mean_adj_rsq = mean(adj.r.squared),
             mean_aic = mean(AIC),
             mean_bic = mean (BIC)) |>
  kable(digits = 3, caption = "wflow4")
```

Here are the results from our 3-fold cross validation on each of the four different models:

| Model \# | Mean Adjusted $R^2$ | Mean AIC | Mean BIC |
|----------|---------------------|----------|----------|
| 1        | 0.269               | 610.982  | 676.177  |
| 2        | 0.333               | 580.208  | 633.100  |
| 3        | 0.265               | 606.73   | 649.782  |
| 4        | 0.303               | 603.144  | 694.162  |

We want a model with the highest mean adjusted $R^2$ value and the lowest mean AIC and BIC values. From these statistics, it is clear that Model #2 (imdb \~ network + monster.amount + unmask_villain with an interaction between monster.amount and unmask_villain) had the highest mean adjusted $R^2$ and the lowest AIC and BIC values. Therefore, we will use this model as our final model.

# Results:

Here is the output from our final model:

```{r finalmodel, out.width = "75%"}

scooby_fit <- wflow2 |>
  fit(data = train_data)

tidy(scooby_fit) |>
  kable(digits = 3)
```

This is the model output for our final model, where we predicted `imdb` with `network`, `monster.amount`, and `unmask_villain`, with an interaction between `monster.amount` and `unmask_villain`. From the p-values of the coefficients, we see that 7 of 18 predictor variables have significant values when using a threshold of 0.05.

Most of the low p-values in coefficients come from `network`. The baseline category for `network` in our model was ABC. When the network is Boomerang, Cartoon Network, CBS, or The WB, we expect the IMDb rating to increase by 0.438, 0.686, 0.691, and 0.202 points, respectively, compared to if the network is ABC, holding all other variables constant. Episodes on other networks (which we set as having 30 or fewer total episodes) were expected to have a lower IMDb rating, being 0.872 points less than an episode on ABC. This shows that episodes that aired on bigger networks tended to receive better ratings. However, it is important to note that the coefficient for The WB did not have a significant p-value.

We also had a significant p-value for `monster.amount`. From the output, we observe that for each additional monster in the episode, we expect the IMDb rating to decrease by -0.146 points, holding all other variables constant. This shows that as monsters increase, episodes tend to not fare as well. Interestingly, `monster.amount_x_unmask_villainVelma` was significant while none of the other interactions were. We find that in episodes where Velma unmasks the villain, we expect the IMDb rating to increase by 0.038 points for every additional monster, holding all other variables constant.

Another significant coefficient value that is worthy to note is `unmask_villain_None`. From our earlier EDA, we did see that 'None' was the largest category for `unmask_villain`, so the coefficient value may be significant only because there was a large amount of data for it. However, these episodes tend to not fare very well as we expect the IMDb rating to be -0.310 points lower if no one unmasks the villain compared to episodes where Daphne unmasks the villain, holding all other variables constant. Though all the other `unmask_vilain` coefficients were not significant, we notice that episodes where Daphne (our baseline) unmasked the villain seem to fare the best as all the coefficients, though not significant, are negative. We proceed by checking model conditions for inference. Specifically, this includes linearity, constant variance, normality, and independence.

```{r}

predictions <- predict(scooby_fit, new_data = train_data, type = "raw")
residuals <- train_data$imdb - predictions

scooby_aug <- data.frame(
  .fitted = predictions,
  .resid = residuals
) |>
  bind_cols(train_data)
```

```{r conditions}
#| warning: false

p1 <- ggplot(data = scooby_aug, aes(x = .fitted, y = .resid)) +
  geom_point(size = 0.5) +
  geom_hline(yintercept = 0, color = "red", linetype = "dashed") +
  labs(title = "Residuals vs. Predicted Values",
       x = "Predicted values", 
       y = "Residuals") +
  theme_minimal() +
    theme(plot.title = element_text(size=6)) +
  theme(plot.subtitle = element_text(size=6)) +
  theme(legend.title = element_text(size=6)) +
  theme(legend.text = element_text(size=6)) +
  theme(axis.title.x = element_text(size=6)) +
  theme(axis.title.y = element_text(size=6))

p2 <- ggplot(data = scooby_aug, aes(x = network, y = .resid)) +
  geom_point(size = 0.5) +
  geom_hline(yintercept = 0, color = "red", linetype = "dashed") +
  labs(title = "Network", 
       x = "Network", 
       y = "Residuals") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1, size = 3.5)) +
      theme(plot.title = element_text(size=6)) +
  theme(plot.subtitle = element_text(size=6)) +
  theme(legend.title = element_text(size=6)) +
  theme(legend.text = element_text(size=6)) +
  theme(axis.title.x = element_text(size=6)) +
  theme(axis.title.y = element_text(size=6)) +
  theme(axis.text.x = element_text(size = 4))

p3 <- ggplot(data = scooby_aug, aes(x = monster.amount, y = .resid)) +
  geom_point(size = 0.5) +
  geom_hline(yintercept = 0, color = "red", linetype = "dashed") +
  labs(title = "Monster Amount",
       x = "Monster Amount") +
  theme_minimal() +
      theme(plot.title = element_text(size=6)) +
  theme(plot.subtitle = element_text(size=6)) +
  theme(legend.title = element_text(size=6)) +
  theme(legend.text = element_text(size=6)) +
  theme(axis.title.x = element_text(size=6)) +
  theme(axis.title.y = element_text(size=6)) +
  theme(axis.title.y = element_blank()) +
  theme(axis.text.x = element_text(size = 4))

p4 <- ggplot(data = scooby_aug, aes(x = unmask_villain, y = .resid)) +
  geom_point(size = 0.5) +
  geom_hline(yintercept = 0, color = "red", linetype = "dashed") +
  labs(title = "Unmask Villain", 
       x = "Unmasked By") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1, size = 4)) +
  theme(plot.title = element_text(size=6)) +
  theme(plot.subtitle = element_text(size=6)) +
  theme(legend.title = element_text(size=6)) +
  theme(legend.text = element_text(size=6)) +
  theme(axis.title.x = element_text(size=6)) +
  theme(axis.title.y = element_text(size=6)) +
  theme(axis.title.y = element_blank())
```

```{r normality}
#| warning: false
#| message: false

p5 <- scooby_aug |>
  ggplot(aes(x = .resid)) +
  geom_histogram() +
  labs(title = "Distribution of Residuals",
       x = "Residuals",
       y = "Frequency") +
  theme_minimal() +
    theme(plot.title = element_text(size=6)) +
  theme(plot.subtitle = element_text(size=6)) +
  theme(legend.title = element_text(size=6)) +
  theme(legend.text = element_text(size=6)) +
  theme(axis.title.x = element_text(size=8)) +
  theme(axis.title.y = element_text(size=8))
```

```{r independence, out.width = "75%"}
#| warning: false

p6 <- ggplot(scooby_aug, aes(y = .resid, x = 1:nrow(scooby_aug))) +
  geom_line() +
  geom_point(size = 0.05) +
  geom_hline(yintercept = 0, color = "red", linetype = "dashed") +
  labs(title = "Residuals Over Time",
       x = "Order of Episodes",
       y = "Residuals") +
  theme_minimal() +
    theme(plot.title = element_text(size=6)) +
  theme(plot.subtitle = element_text(size=6)) +
  theme(legend.title = element_text(size=6)) +
  theme(legend.text = element_text(size=6)) +
  theme(axis.title.x = element_text(size=8)) +
  theme(axis.title.y = element_text(size=8))
```

```{r, out.width = "102%"}

(p1
/
(p2 | p3 | p4) | (p6/p5))
```

From the residuals vs. predicted values plot as well as the three plots of residuals vs. each of our three predictor variables, we observe that there does not seem to be a discernible, non-linear pattern in each of these plots. Therefore, the **linearity** condition is satisfied. Also from the residuals vs. predicted values plot, the vertical spread seems to be approximately constant across the x-axis. Though there are outliers in this plot, it is roughly the same above and below the 0-line. Therefore, the **constant variance** condition is satisfied. From the histogram showing the distribution of residuals, we observe that the distribution of the residuals is approximately unimodal and symmetric. The sample size of 452 observations in our training data is also sufficiently large to relax this condition if it was not satisfied. Therefore, the **normality** condition is satisfied. Since our data is collected over time, we examined a scatterplot of the residuals versus the order in which the data were collected. However, no clear pattern was observed in the residuals vs. order of data collection plot. Therefore, the **independence** condition is satisfied. Since all four conditions are satisfied, we continue using our model for predictions in both our training and testing sets.

```{r predictions}

train_pred <- predict(scooby_fit, train_data) |>
  bind_cols(train_data)

test_pred <- predict(scooby_fit, test_data) |>
  bind_cols(test_data)
```

```{r rsqrmse}

rsq_train <- rsq(train_pred, truth = imdb, estimate = .pred)
rsq_test <- rsq(test_pred, truth = imdb, estimate = .pred)

rmse_train <- rmse(train_pred, truth = imdb, estimate = .pred)
rmse_test <- rmse(test_pred, truth = imdb, estimate = .pred)
```

| Dataset  | $R^2$ | RMSE  |
|----------|-------|-------|
| Training | 0.483 | 0.554 |
| Testing  | 0.506 | 0.423 |

The model's $R^2$ value on the training data is approximately 0.483, which means that approximately 48.3 percent of the variation in the response variable is explained by our regression model. However, the model's $R^2$ value on the testing data is approximately 0.506, which is surprisingly higher than the value for our training data. Since the $R^2$ values are relatively close, we are not too concerned about our model having overfit the data. The same trend is observed in our RMSE values, as the RMSE for the training data is 0.554 points, while it is 0.423 points for the testing data. These values show that our model might not have the best predictive power, as only around half of the variation is accounted for. However, considering that we only took into account 3 total variables to predict IMDb rating, the model performs pretty well.

# Discussion and Conclusion:

All in all, from our model, we see that `network` and `monster.amount` seem to be significant when predicting IMDb ratings for different Scooby-Doo episodes. Episodes containing fewer monsters as well as episodes airing on networks like CBS, Cartoon Network, and Boomerang tended to have the highest IMDb ratings. We observe that the variable, `unmask_villain`, as well as its interaction with `monster.amount`, carry very few significant coefficients, so we may reconsider including this variable as a predictor variable in future models. However, for this project, since we were especially interested in using `unmask_villain` as a predictor variable, we retained it in our final model. According to the interpretation of the coefficients in the Results section, the model results do not align with our initial hypothesis on the `monster.amount`, if only considering significant coefficients. Increasing the amount of monsters in an episode seems to decrease the IMDb rating. Similarly, our hypothesis about the IMDb rating being higher when Fred unmasked the villain didn't hold either. Though not having significant coefficients, it seemed that episodes where Daphne unmasked the villain did better. However, our hypothesis about Cartoon Network almost holds, as it sees the second-highest increase in IMDb rating, falling short of CBS. Since both of these are pretty well-known, large cable or television companies, it is likely that these larger companies with previously established reputations are what allow the IMDb ratings to be higher for their respective episodes, though further analysis would be needed.

Placing the comparison of these results with our intuition and initial hypotheses in a larger context, we conclude that IMDb ratings for any TV series or movie are not easily predicted as people's preferences are completely subjective; thus, more variables are needed in the model to account for such variability. This naturally leads to a discussion of the limitations of this particular dataset and our analysis methods. Since our data was collected by one individual while watching each episode, there was likely some human error. The individual likely missed some details in episodes, leading to not entirely accurate data. This could be mitigated by a more robust data collection process. For example, more than one person could watch each episode and their results could be compared or averaged. The dataset also lacks more informative variables that can quantify information from each episode. One limitation of our analysis is that we used many of the variables as they naturally appeared in the dataset. As part of our future work, it could have been helpful to mean-center our numeric variable or transform it in some way to see how that changes its relationship with our response variable. It would have also been beneficial to relevel `unmask_villain` so that the baseline was either `unmask_villain_None` or `unmask_villain_other`. By doing this, we could arrive at clearer conclusions and interpretations on the effect of having one of the main characters in the show unmask the villain or having someone unmasking the villain at all. Another limitation is the limited range of variables we chose from. Our data had a vast amount of possible predictor variables to choose from, but many were difficult to use due to the nature of the input. So, it is likely we missed a relationship between some of the variables we did not use and each episode's IMDb ratings. In future work, in order to make do with the limited variables we have, there are a few feature engineering steps that we could've used. For example, since the date aired is in the dataset, it could have been insightful to extract month, day of week, or any holidays from the variable `date.aired` in our feature engineering, as this step would make date a reasonable predictor to test. Month might be interesting to look at to see if there is any relationship between IMDb ratings for months during the academic year vs. during the summer, as engagement for the episode would likely change with whether the episode aired while children were in school vs. while children were on break and possibly be reflected by the IMDb rating.

In the future, we would also like to explore the other variables in the dataset and try to find an even better model that predicts IMDb ratings. Of course, it would be beneficial to do a more thorough data cleaning process so that we would be able to use the variables that we deemed as unfit to use for this analysis. For future work, we also think it would be helpful to explore data from other TV shows and attempt to find broader predictor variables that might be able to predict IMDb ratings across various animated TV shows. If we were to do this, our findings could aid future animated TV shows, and not just more reboots of Scooby-Doo, in considering what elements to add to their show that would bring higher IMDb ratings.
